"""
Module de t√©l√©chargement des donn√©es historiques.
Utilise yfinance comme source principale avec support pour MT5.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import yfinance as yf
from tqdm import tqdm
import os
import sys

# Sources de donn√©es alternatives
try:
    from polygon import RESTClient as PolygonClient
except ImportError:
    PolygonClient = None

try:
    import finnhub
except ImportError:
    finnhub = None

try:
    import requests
except ImportError:
    requests = None

try:
    from alpha_vantage.foreignexchange import ForeignExchange
except ImportError:
    ForeignExchange = None

# Ajouter le chemin parent pour les imports

from quantum.shared.config.settings import config


class DataDownloader:
    """
    T√©l√©charge et g√®re les donn√©es historiques du march√©.
    Supporte le backfilling massif sur plusieurs ann√©es.
    """
    
    def __init__(self, cache_dir: str = None):
        """
        Initialise le t√©l√©chargeur de donn√©es.

        Args:
            cache_dir: R√©pertoire de cache pour les donn√©es t√©l√©charg√©es
        """
        self.cache_dir = cache_dir or config.system.DATA_DIR
        self.symbols = config.symbols.ACTIVE_SYMBOLS
        self.alpha_vantage_key = os.getenv('ALPHA_VANTAGE_API_KEY') or config.data.ALPHA_VANTAGE_API_KEY
        self.polygon_key = os.getenv('POLYGON_API_KEY') or config.data.POLYGON_API_KEY
        self.finnhub_key = os.getenv('FINNHUB_API_KEY') or config.data.FINNHUB_API_KEY
        self._ensure_cache_dir()
    
    def _ensure_cache_dir(self):
        """Cr√©e le r√©pertoire de cache s'il n'existe pas."""
        os.makedirs(self.cache_dir, exist_ok=True)
    
    def download_historical(
        self,
        symbol: str,
        years: int = None,
        interval: str = "1h"
    ) -> pd.DataFrame:
        """
        T√©l√©charge les donn√©es historiques pour un symbole donn√©.
        
        Args:
            symbol: Symbole √† t√©l√©charger (ex: "EURUSD=X")
            years: Nombre d'ann√©es d'historique
            interval: Intervalle des bougies
        
        Returns:
            DataFrame avec colonnes OHLCV index√©es par datetime
        """
        years = years or config.data.HISTORICAL_YEARS
        
        # Calcul des dates
        end_date = datetime.now()
        start_date = end_date - timedelta(days=years * 365)
        
        print(f"üì• T√©l√©chargement de {symbol} ({interval}) depuis {start_date.date()}...")
        
        # Essayer les sources dans l'ordre: yfinance -> Polygon -> Finnhub -> Alpha Vantage
        sources = [
            ("yfinance", self._download_from_yfinance),
            ("Polygon", self._download_from_polygon),
            ("Finnhub", self._download_from_finnhub),
            ("Alpha Vantage", self._try_alpha_vantage_fallback)
        ]

        for source_name, download_func in sources:
            try:
                print(f"üì° Tentative depuis {source_name}...")
                df = download_func(symbol, start_date, end_date, interval, years)

                if not df.empty:
                    # Nettoyage des colonnes
                    df = self._clean_dataframe(df)

                    # Sauvegarde en cache
                    cache_file = self._get_cache_path(symbol, interval)
                    df.to_parquet(cache_file)
                    print(f"‚úÖ {len(df)} bougies t√©l√©charg√©es depuis {source_name} et mises en cache")
                    return df

            except Exception as e:
                print(f"‚ö†Ô∏è √âchec {source_name} pour {symbol}: {e}")
                continue

        print(f"‚ùå Aucune source n'a pu fournir des donn√©es pour {symbol}")
        return pd.DataFrame()

    def _download_from_yfinance(self, symbol: str, start_date: datetime, end_date: datetime, interval: str, years: int) -> pd.DataFrame:
        """T√©l√©charge depuis yfinance."""
        ticker = yf.Ticker(symbol)
        df = ticker.history(
            start=start_date,
            end=end_date,
            interval=interval,
            auto_adjust=True
        )
        return df

    def _download_from_polygon(self, symbol: str, start_date: datetime, end_date: datetime, interval: str, years: int) -> pd.DataFrame:
        """T√©l√©charge depuis Polygon.io."""
        if not self.polygon_key or not PolygonClient:
            return pd.DataFrame()

        try:
            client = PolygonClient(self.polygon_key)

            # Convertir l'intervalle
            interval_map = {
                "1m": "minute", "5m": "minute", "15m": "minute", "30m": "minute",
                "1h": "hour", "4h": "hour", "1d": "day"
            }
            timespan = interval_map.get(interval, "day")
            multiplier = 1
            if interval in ["5m", "15m", "30m"]:
                multiplier = int(interval[:-1])
            elif interval == "4h":
                multiplier = 4

            # T√©l√©charger
            aggs = client.get_aggs(
                symbol, multiplier, timespan,
                start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
            )

            if not aggs:
                return pd.DataFrame()

            # Convertir en DataFrame
            data = []
            for agg in aggs:
                data.append({
                    'timestamp': pd.to_datetime(agg.timestamp, unit='ms'),
                    'Open': agg.open,
                    'High': agg.high,
                    'Low': agg.low,
                    'Close': agg.close,
                    'Volume': agg.volume
                })

            df = pd.DataFrame(data)
            df.set_index('timestamp', inplace=True)
            return df

        except Exception as e:
            print(f"Erreur Polygon: {e}")
            return pd.DataFrame()

    def _download_from_finnhub(self, symbol: str, start_date: datetime, end_date: datetime, interval: str, years: int) -> pd.DataFrame:
        """T√©l√©charge depuis Finnhub."""
        if not self.finnhub_key or not finnhub:
            return pd.DataFrame()

        try:
            client = finnhub.Client(api_key=self.finnhub_key)

            # Convertir les dates en timestamp
            from_ts = int(start_date.timestamp())
            to_ts = int(end_date.timestamp())

            # R√©solution
            resolution_map = {
                "1m": "1", "5m": "5", "15m": "15", "30m": "30",
                "1h": "60", "1d": "D"
            }
            resolution = resolution_map.get(interval, "D")

            # T√©l√©charger
            data = client.stock_candles(symbol, resolution, from_ts, to_ts)

            if not data or data['s'] != 'ok':
                return pd.DataFrame()

            # Convertir en DataFrame
            df = pd.DataFrame({
                'timestamp': pd.to_datetime(data['t'], unit='s'),
                'Open': data['o'],
                'High': data['h'],
                'Low': data['l'],
                'Close': data['c'],
                'Volume': data['v']
            })
            df.set_index('timestamp', inplace=True)
            return df

        except Exception as e:
            print(f"Erreur Finnhub: {e}")
            return pd.DataFrame()

    def _download_from_alpha_vantage(
        self,
        from_symbol: str,
        to_symbol: str,
        interval: str = "1d",
        years: int = 2
    ) -> pd.DataFrame:
        """
        T√©l√©charge les donn√©es forex depuis Alpha Vantage.

        Args:
            from_symbol: Devise source (ex: "EUR")
            to_symbol: Devise cible (ex: "USD")
            interval: Intervalle (1min, 5min, 15min, 30min, 60min)
            years: Nombre d'ann√©es

        Returns:
            DataFrame avec colonnes OHLCV
        """
        if not self.alpha_vantage_key:
            print("‚ùå Cl√© API Alpha Vantage non configur√©e")
            return pd.DataFrame()

        try:
            # Mapping des intervalles
            interval_map = {
                "1m": "1min",
                "5m": "5min",
                "15m": "15min",
                "30m": "30min",
                "1h": "60min"
            }
            av_interval = interval_map.get(interval, "60min")

            # Initialiser le client
            fx = ForeignExchange(key=self.alpha_vantage_key)

            # Pour le free tier, utiliser les donn√©es daily (intraday est premium)
            data, _ = fx.get_currency_exchange_daily(
                from_symbol=from_symbol,
                to_symbol=to_symbol,
                outputsize='full'
            )

            if not data:
                print(f"‚ö†Ô∏è Aucune donn√©e Alpha Vantage pour {from_symbol}/{to_symbol}")
                return pd.DataFrame()

            # Convertir en DataFrame
            df = pd.DataFrame.from_dict(data, orient='index')
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            # Renommer les colonnes
            df = df.rename(columns={
                '1. open': 'Open',
                '2. high': 'High',
                '3. low': 'Low',
                '4. close': 'Close',
                '5. volume': 'Volume'
            })

            # Convertir en num√©rique
            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # Filtrer par p√©riode
            end_date = datetime.now()
            start_date = end_date - timedelta(days=years * 365)
            df = df[df.index >= start_date]

            print(f"‚úÖ {len(df)} bougies t√©l√©charg√©es depuis Alpha Vantage pour {from_symbol}/{to_symbol}")

            return df

        except Exception as e:
            print(f"‚ùå Erreur Alpha Vantage pour {from_symbol}/{to_symbol}: {e}")
            return pd.DataFrame()

    def _try_alpha_vantage_fallback(self, symbol: str, start_date: datetime, end_date: datetime, interval: str, years: int) -> pd.DataFrame:
        """
        Tente de t√©l√©charger depuis Alpha Vantage pour les symboles forex.

        Args:
            symbol: Symbole (ex: "EURUSD=X")
            start_date: Date de d√©but
            end_date: Date de fin
            interval: Intervalle
            years: Nombre d'ann√©es

        Returns:
            DataFrame ou vide si √©chec
        """
        # Parser le symbole forex
        if '=' in symbol:
            base_symbol = symbol.split('=')[0]
        else:
            base_symbol = symbol

        # Pour EURUSD=X -> EUR/USD
        if len(base_symbol) == 6 and base_symbol[:3] != base_symbol[3:]:
            from_symbol = base_symbol[:3]
            to_symbol = base_symbol[3:]
            df = self._download_from_alpha_vantage(from_symbol, to_symbol, interval, years)
            # Filtrer par dates
            if not df.empty:
                df = df[(df.index >= start_date) & (df.index <= end_date)]
            return df

        return pd.DataFrame()
    
    def download_all_symbols(
        self,
        interval: str = "1h",
        years: int = None
    ) -> Dict[str, pd.DataFrame]:
        """
        T√©l√©charge les donn√©es pour tous les symboles configur√©s.
        
        Args:
            interval: Intervalle des bougies
            years: Nombre d'ann√©es d'historique
        
        Returns:
            Dictionnaire {symbole: DataFrame}
        """
        data = {}
        
        for symbol in tqdm(self.symbols, desc="T√©l√©chargement des symboles"):
            df = self.download_historical(symbol, years, interval)
            if not df.empty:
                data[symbol] = df
        
        return data
    
    def download_multiple_timeframes(
        self,
        symbol: str,
        timeframes: List[str] = None,
        years: int = None
    ) -> Dict[str, pd.DataFrame]:
        """
        T√©l√©charge les donn√©es pour plusieurs timeframes.
        
        Note: yfinance a des limitations sur les intervalles historiques:
        - 1m/2m/5m/15m: max 7 jours
        - 30m/1h: max 730 jours
        - 1d/1wk/1mo: illimit√©
        
        Args:
            symbol: Symbole √† t√©l√©charger
            timeframes: Liste des timeframes
            years: Nombre d'ann√©es
        
        Returns:
            Dictionnaire {timeframe: DataFrame}
        """
        timeframes = timeframes or config.timeframes.TIMEFRAMES
        data = {}
        
        for tf in timeframes:
            # Adaptation des ann√©es selon le timeframe
            max_years = self._get_max_years_for_interval(tf)
            actual_years = min(years or config.data.HISTORICAL_YEARS, max_years)
            
            df = self.download_historical(symbol, actual_years, tf)
            if not df.empty:
                data[tf] = df
        
        return data
    
    def resample_to_timeframe(
        self,
        df: pd.DataFrame,
        target_timeframe: str
    ) -> pd.DataFrame:
        """
        Resample les donn√©es vers un timeframe cible.
        
        Args:
            df: DataFrame source
            target_timeframe: Timeframe cible
        
        Returns:
            DataFrame resampl√©
        """
        resample_rule = config.timeframes.RESAMPLE_MAP.get(target_timeframe, target_timeframe)
        
        resampled = df.resample(resample_rule).agg({
            'Open': 'first',
            'High': 'max',
            'Low': 'min',
            'Close': 'last',
            'Volume': 'sum'
        }).dropna()
        
        return resampled
    
    def load_from_cache(
        self,
        symbol: str,
        interval: str = "1h"
    ) -> Optional[pd.DataFrame]:
        """
        Charge les donn√©es depuis le cache si elles ne sont pas trop vieilles.
        
        Args:
            symbol: Symbole √† charger
            interval: Intervalle des bougies
        
        Returns:
            DataFrame ou None si non trouv√© ou expir√©
        """
        cache_file = self._get_cache_path(symbol, interval)
        
        if os.path.exists(cache_file):
            # V√©rifier l'√¢ge du cache
            cache_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            expiry_hours = config.data.CACHE_EXPIRY_HOURS
            
            if datetime.now() - cache_time < timedelta(hours=expiry_hours):
                print(f"üì¶ Chargement depuis le cache: {symbol} ({interval})")
                return pd.read_parquet(cache_file)
            else:
                print(f"üîÑ Cache expir√© pour {symbol} ({interval}), re-t√©l√©chargement n√©cessaire")
        
        return None
    
    def get_data(
        self,
        symbol: str,
        interval: str = "1h",
        force_download: bool = False
    ) -> pd.DataFrame:
        """
        R√©cup√®re les donn√©es (cache ou t√©l√©chargement).
        
        Args:
            symbol: Symbole √† r√©cup√©rer
            interval: Intervalle des bougies
            force_download: Forcer le re-t√©l√©chargement
        
        Returns:
            DataFrame avec les donn√©es
        """
        if not force_download:
            cached = self.load_from_cache(symbol, interval)
            if cached is not None:
                return cached
        
        return self.download_historical(symbol, interval=interval)
    
    def validate_data(self, df: pd.DataFrame) -> Dict:
        """
        Valide l'int√©grit√© des donn√©es t√©l√©charg√©es.
        
        Args:
            df: DataFrame √† valider
        
        Returns:
            Dictionnaire avec les r√©sultats de validation
        """
        validation = {
            "total_rows": len(df),
            "null_count": df.isnull().sum().sum(),
            "null_percent": (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100,
            "date_range": f"{df.index.min()} - {df.index.max()}",
            "duplicate_indices": df.index.duplicated().sum(),
            "price_anomalies": self._detect_price_anomalies(df),
            "is_valid": True
        }
        
        # Crit√®res de validit√©
        if validation["null_percent"] > 5:
            validation["is_valid"] = False
            validation["issues"] = validation.get("issues", []) + ["Trop de valeurs nulles"]
        
        if validation["duplicate_indices"] > 0:
            validation["is_valid"] = False
            validation["issues"] = validation.get("issues", []) + ["Index dupliqu√©s d√©tect√©s"]
        
        return validation
    
    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Nettoie et standardise le DataFrame."""
        # Renommer les colonnes si n√©cessaire
        df.columns = [col.capitalize() for col in df.columns]
        
        # Garder seulement OHLCV
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        available_cols = [col for col in required_cols if col in df.columns]
        df = df[available_cols].copy()
        
        # Supprimer les lignes avec des valeurs nulles
        df = df.dropna()
        
        # Supprimer les doublons d'index
        df = df[~df.index.duplicated(keep='first')]
        
        # Trier par date
        df = df.sort_index()
        
        return df
    
    def _get_cache_path(self, symbol: str, interval: str) -> str:
        """G√©n√®re le chemin du fichier cache."""
        safe_symbol = symbol.replace("=", "_").replace("/", "_")
        return os.path.join(self.cache_dir, f"{safe_symbol}_{interval}.parquet")
    
    def _get_max_years_for_interval(self, interval: str) -> float:
        """Retourne le maximum d'ann√©es disponibles pour un intervalle."""
        limits = {
            "1m": 0.16,  # ~60 jours
            "2m": 0.16,
            "5m": 0.16,
            "15m": 0.16,
            "30m": 2,
            "1h": 1.92,  # ~700 jours
            "4h": 2,
            "1d": 10,
            "1wk": 10,
            "1mo": 10
        }
        return limits.get(interval, 2)
    
    def get_current_price(self, symbol: str) -> Optional[float]:
        """
        R√©cup√®re le prix actuel d'un symbole.

        Args:
            symbol: Symbole (ex: "EURUSD=X")

        Returns:
            Prix actuel ou None si √©chec
        """
        try:
            ticker = yf.Ticker(symbol)
            # R√©cup√©rer les donn√©es r√©centes (derni√®re journ√©e)
            data = ticker.history(period="1d", interval="1m")
            if not data.empty:
                return float(data['Close'].iloc[-1])
        except Exception as e:
            print(f"‚ùå Erreur r√©cup√©ration prix actuel pour {symbol}: {e}")

        return None

    def _detect_price_anomalies(self, df: pd.DataFrame) -> int:
        """D√©tecte les anomalies de prix (variations extr√™mes)."""
        if 'Close' not in df.columns:
            return 0

        returns = df['Close'].pct_change()
        # Variations > 10% en une bougie = potentielle anomalie
        anomalies = (returns.abs() > 0.10).sum()
        return int(anomalies)


if __name__ == "__main__":
    # Test du module
    downloader = DataDownloader()

    # T√©l√©charger tous les symboles actifs
    print("üìä Test du t√©l√©chargement pour tous les symboles actifs...")
    all_data = downloader.download_all_symbols(years=2, interval="1h")

    for symbol, data in all_data.items():
        print(f"\n{symbol} shape: {data.shape}")
        if not data.empty:
            print(data.head(3))
            # Valider les donn√©es
            validation = downloader.validate_data(data)
            print(f"Validation: {validation}")
        else:
            print("‚ùå Aucune donn√©e re√ßue")
        print("-" * 50)
